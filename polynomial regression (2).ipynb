{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "# inputs = gap, speed, lead speed\n",
    "# output = acceleration\n",
    "inputs = df.iloc[:, 1:4].values\n",
    "output = df.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [16.49585283  2.53829175 12.43940968]\n",
      " [24.31982909  3.04930868  1.26702903]\n",
      " ...\n",
      " [24.99147509 22.31983849  9.59825696]\n",
      " [35.49263862 28.06505694 33.21846164]\n",
      " [13.19718427 24.2861917  14.25926874]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.           0.98524898   0.91058088 ... -30.79518347   0.23091303\n",
      " -90.15209714]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        gap      speed  lead_speed  acceleration  new_speed  \\\n",
      "0           0   0.000000   0.000000    0.000000      0.000000   0.000000   \n",
      "1           1  16.495853   2.538292   12.439410      0.985249   2.636817   \n",
      "2           2  24.319829   3.049309    1.267029      0.910581   3.140367   \n",
      "3           3   3.451395  11.844214   26.573875      0.639911  11.908205   \n",
      "4           4  47.824531  15.410674   12.011722      0.272340  15.437908   \n",
      "\n",
      "    delta_x  \n",
      "0  0.000000  \n",
      "1  0.258755  \n",
      "2  0.309484  \n",
      "3  1.187621  \n",
      "4  1.542429  \n",
      "     Unnamed: 0       gap      speed  lead_speed  acceleration    new_speed  \\\n",
      "61           61  3.806773  31.915501    1.125740 -13063.269510 -1274.411450   \n",
      "128         128  3.125254  32.199805    5.378393 -15316.840137 -1499.484209   \n",
      "225         225  2.336744  32.579616    4.457591 -30578.743886 -3025.294773   \n",
      "334         334  2.459953  31.819590   12.739084 -13112.037125 -1279.384122   \n",
      "764         764  2.224509  31.039152    3.263967 -29953.637865 -2964.324635   \n",
      "\n",
      "        delta_x  \n",
      "61   -62.124797  \n",
      "128  -73.364220  \n",
      "225 -149.635758  \n",
      "334  -62.378227  \n",
      "764 -146.664274  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "# check acceleration values with Yashar\n",
    "print(df[df['acceleration']<-10000].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(inputs,output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression using kernel and linear regression\n",
    "\n",
    "### To do: understand how the polynomial transform works. On some rows, reproduce input_augmented from input. (if possible for degree = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "input_augmented = poly_reg.fit_transform(inputs)\n",
    "# poly_reg.fit(input_augmented, output)\n",
    "\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(input_augmented,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 35)\n",
      "{'degree': 4, 'include_bias': True, 'interaction_only': False, 'order': 'C'}\n"
     ]
    }
   ],
   "source": [
    "print(input_augmented.shape)\n",
    "print(poly_reg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.96967012e-09  3.74953253e+02 -9.20186014e+01  8.09118238e+01\n",
      " -2.85719076e+01  2.09853442e+01 -1.69779932e+01 -6.05561401e+00\n",
      "  6.74123780e+00 -1.34861473e+00  7.82988591e-01 -9.89422186e-01\n",
      "  7.71501609e-01  6.40512244e-01 -7.74690850e-01  2.14306370e-01\n",
      " -1.86967636e-01  3.07246760e-01 -1.26104161e-01 -7.78552120e-03\n",
      " -7.02698905e-03  1.23857902e-02 -9.48350813e-03 -1.17947790e-02\n",
      "  1.51038322e-02 -4.70422058e-03  6.16588288e-03 -1.15731445e-02\n",
      "  5.84367706e-03 -2.44086036e-04 -1.38417984e-03  3.53731864e-03\n",
      " -2.20065928e-03 -1.32796031e-04  2.76768109e-04]\n"
     ]
    }
   ],
   "source": [
    "print(lin_reg2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PolynomialFeatures in module sklearn.preprocessing.data:\n",
      "\n",
      "class PolynomialFeatures(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, order='C')\n",
      " |  \n",
      " |  Generate polynomial and interaction features.\n",
      " |  \n",
      " |  Generate a new feature matrix consisting of all polynomial combinations\n",
      " |  of the features with degree less than or equal to the specified degree.\n",
      " |  For example, if an input sample is two dimensional and of the form\n",
      " |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  degree : integer\n",
      " |      The degree of the polynomial features. Default = 2.\n",
      " |  \n",
      " |  interaction_only : boolean, default = False\n",
      " |      If true, only interaction features are produced: features that are\n",
      " |      products of at most ``degree`` *distinct* input features (so not\n",
      " |      ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).\n",
      " |  \n",
      " |  include_bias : boolean\n",
      " |      If True (default), then include a bias column, the feature in which\n",
      " |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      " |      intercept term in a linear model).\n",
      " |  \n",
      " |  order : str in {'C', 'F'}, default 'C'\n",
      " |      Order of output array in the dense case. 'F' order is faster to\n",
      " |      compute, but may slow down subsequent estimators.\n",
      " |  \n",
      " |      .. versionadded:: 0.21\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.preprocessing import PolynomialFeatures\n",
      " |  >>> X = np.arange(6).reshape(3, 2)\n",
      " |  >>> X\n",
      " |  array([[0, 1],\n",
      " |         [2, 3],\n",
      " |         [4, 5]])\n",
      " |  >>> poly = PolynomialFeatures(2)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      " |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      " |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      " |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.],\n",
      " |         [ 1.,  2.,  3.,  6.],\n",
      " |         [ 1.,  4.,  5., 20.]])\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  powers_ : array, shape (n_output_features, n_input_features)\n",
      " |      powers_[i, j] is the exponent of the jth input in the ith output.\n",
      " |  \n",
      " |  n_input_features_ : int\n",
      " |      The total number of input features.\n",
      " |  \n",
      " |  n_output_features_ : int\n",
      " |      The total number of polynomial output features. The number of output\n",
      " |      features is computed by iterating over all suitably sized combinations\n",
      " |      of input features.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Be aware that the number of features in the output array scales\n",
      " |  polynomially in the number of features of the input array, and\n",
      " |  exponentially in the degree. High degrees can cause overfitting.\n",
      " |  \n",
      " |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      " |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PolynomialFeatures\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, degree=2, interaction_only=False, include_bias=True, order='C')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute number of output features.\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : instance\n",
      " |  \n",
      " |  get_feature_names(self, input_features=None)\n",
      " |      Return feature names for output features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : list of string, length n_features, optional\n",
      " |          String names for input features if available. By default,\n",
      " |          \"x0\", \"x1\", ... \"xn_features\" is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      output_feature_names : list of string, length n_output_features\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform data to polynomial features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or CSR/CSC sparse matrix, shape [n_samples, n_features]\n",
      " |          The data to transform, row by row.\n",
      " |      \n",
      " |          Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
      " |          required if the degree is 4 or higher. If the degree is less than\n",
      " |          4 and the input format is CSC, it will be converted to CSR, have\n",
      " |          its polynomial features generated, then converted back to CSC.\n",
      " |      \n",
      " |          If the degree is 2 or 3, the method described in \"Leveraging\n",
      " |          Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
      " |          Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
      " |          used, which is much faster than the method used on CSC input. For\n",
      " |          this reason, a CSC input will be converted to CSR, and the output\n",
      " |          will be converted back to CSC prior to being returned, hence the\n",
      " |          preference of CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      XP : np.ndarray or CSR/CSC sparse matrix, shape [n_samples, NP]\n",
      " |          The matrix of features, where NP is the number of polynomial\n",
      " |          features generated from the combination of inputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  powers_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "[2057283  770952 2253086 1063261  951530 1632481 2965419 1726513 1495767\n",
      " 1156289  620715  432841 2495690 1064077 2819715 2304654 2329351 2482855\n",
      "  801292 2947074  982382  308339 1842054 2753138 2684224   89931 1805259\n",
      " 1022642  949015 1989372 2028055  485003 1405746  688082  639576 2198252\n",
      "  992846 2717237 1913010  916959 1796476 2408728   52538 1979945 1883912\n",
      "   74309 1011572 2625160 1951565  364579  680012 2289497 2197095 2551673\n",
      " 1857757 2883814 2519283 2906793 1470299   41724 1850769 1013734 2968360\n",
      "  157657 1026181 2107578 1878244  492651  390656 2810282 2017017 1946412\n",
      "  729099   62014 2864208 2140088  286672 2864807 2047011 2240754 1184557\n",
      " 2815625 2664748  944065 1605274 2597545 2094373 1311431 1229704  662518\n",
      " 1971429  304137   35056 1022765 1918873  792959 1563416 1250693  873244\n",
      " 1044727]\n"
     ]
    }
   ],
   "source": [
    "n = inputs.shape[0]\n",
    "print(n)\n",
    "batch = np.random.choice(n, 100)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[ 9.85275054e-01  9.15150509e-01  7.26647145e-01 -2.01135065e+01\n",
      " -1.67219601e+01  9.62210852e-01  8.51064607e-01 -4.13209616e+01\n",
      " -5.41662775e+00 -8.29507527e-02  8.56089317e-01 -2.06731636e+01\n",
      "  9.95398677e-01 -4.92587082e+01 -1.65718374e+02 -2.37824718e+01\n",
      " -1.36131285e+00 -2.09599320e+01 -3.11141193e+01  7.91955621e-01\n",
      " -1.13347510e+01 -5.68313885e+00  6.17048131e-01 -5.47673883e+01\n",
      " -2.52687451e+02 -3.96103985e+02  9.83875375e-01 -2.95190964e+01\n",
      "  9.86626287e-01 -6.66987918e+00 -7.22790485e+03 -6.00242168e+01\n",
      " -2.05471672e+01  8.84476718e-01 -3.86264021e+01 -3.47094403e+01\n",
      "  9.70807987e-01 -8.55556179e+00 -2.12583964e+01 -6.98886981e+00\n",
      "  7.08910090e-01 -6.68529456e+01 -7.38288151e-01  5.67190157e-01\n",
      " -4.63526338e+02  1.11721971e-01 -3.15939873e+02 -2.95059755e-01\n",
      " -4.95649590e+01  9.45034835e-01  8.22655828e-01 -2.07384853e+01\n",
      " -1.73695633e+00 -2.70995985e+01 -2.13053977e+02  9.89655401e-01\n",
      " -6.20853084e+01 -7.43191589e+00 -2.10541626e-01 -2.96114280e+03\n",
      " -4.59357915e+01  9.96922461e-01  9.97845522e-01 -4.42156384e+00\n",
      "  9.12828373e-01 -6.40525362e+01 -8.59592768e+00  9.37125217e-01\n",
      "  5.72193987e-01  8.21818804e-01  1.27731670e-01  7.70975775e-01\n",
      "  1.04049172e-01  2.13490753e-01 -6.91838592e+01  9.05155140e-01\n",
      "  9.60985872e-01 -2.50788747e+02 -1.71275341e+02  9.47367068e-01\n",
      " -3.41748597e+00 -7.24868394e+03 -8.66600801e+01 -3.49494874e+01\n",
      "  2.67568104e-01  9.58430136e-01 -3.35275575e+01  9.83073215e-01\n",
      " -1.54974618e+00 -1.16392312e+01 -1.62847850e+01  9.75098238e-01\n",
      "  9.84639543e-01  8.38253473e-01 -1.11538108e+02  7.57768822e-01\n",
      " -9.13807895e-01  9.69515812e-01 -2.46113684e+02 -2.08249423e+00]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[batch][:,0].shape)\n",
    "print(output[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEWCAYAAABfdFHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZwdVZ338c+3O92QJpBAA4qEdEDREQbGkRbRGR+RoAZlk9EZY7O5kKFRH3AHMkyCmnGZeURlBCYgsnQrMoqCCDKIoDjjQlBkERkiWYigIQEiISxJ9+/5o+omdW/XXXqp7k739/161eveOrWdWm796pw6t0oRgZmZWVGaxjoDZmY2sTnQmJlZoRxozMysUA40ZmZWKAcaMzMrlAONmZkVyoHGRoWk10l6YKzzMRySZksKSVPGOi9ZkjZI2qeB8cZl/keKpLMlXTLW+bCBHGhsRElaIenwyvSIuD0iXjYWeaokaZGkTekJ+klJ/yPpNWOdr6GKiGkR8dBw55Puu2fS7fJHSZdJmjYSeRwNEfEvEfG+sc6HDeRAYxNajav3b0bENGA34KfANZI0ejkbt45Kt8srgL8GzipiIZKai5ivjU8ONDYqJB0qaXWmf4Wkj0q6W9J6Sd+UtH1m+JGS7sqUOA7MDDtT0u8lPSXpt5Lelhl2sqT/lnSepMeBRbXyFRGbgMuBFwLtkpok/ZOklZLWSLpC0vSc9XmHpDsr0j4i6bvp98skfUXS99N8/kLSizPjvlbSHem63yHptZlht0n6dLreGyR9T1K7pF5Jf07Hn50ZPyS9JP3+Vkm/Tsd7WFLN9a+xXf4I3EQScErL2U7Sv0laJelPki6SNDUz/OOSHpX0iKT3VeTrMkkXSrpB0tPAG2rNT9Kukq5P9//jkm6X1JQO+4SkP6Tb9QFJc9L0RZJ6Mvk5WtJ96Txuk/TyzLCax5+NLAcaG0t/D8wF9gYOBE4GkPRK4FLgH4F24D+A6yRtl073e+B1wHTgXKBH0h6Z+b4aeAjYHVhcKwPpPE8GVkfE2vT7ycAbgH2AacC/50x6HbB39uQFHA9cmemfl+ZvZ2BZKS+SdgG+D3w5Xb8vAN+X1J6Z9p3ACcCewIuBnwFfA3YB7gcWVlmlp4ETgRnAW4FuScfW2gZ5JM0EjkjzXfI54KUkweclad7+OR1/LvBh4PB02OtzZvsukm2wI0kpsur8gI8Aq0lKnC8AzgZC0suADwCviogdgTcDK3Ly/1LgG8AZ6TxuAL4nqTUzWu7xZwWICHfuRqwj+dEfnpN+KMnJPDve8Zn+zwMXpd8vBD5VMf0DwOurLPMu4Jj0+8nAqjp5XAQ8DzwJrAF+BByUDrsFOC0z7suATcAUYDYQwJRMPhen3/cHngC2S/svAy7JzOctwO/S7ycAv6zI08+Ak9PvtwELMsP+H3Bjpv8o4K5MfwAvqbKuXwTOS7+X5b/KvtsAPJWOdwswIx0mkiD24sz4rwGWp98vBT6TGfaSbL7S7XFFZni9+X0SuLZyvdL5riEJaC05+7Un/X4OcHVmWBPwB+DQesefu5HvXKKxsfTHzPeNJKUHgA7gI2mVx5OSngT2Al4EIOnETLXak8BfArtm5vVwA8u+OiJmRMTuEXFYRJSqwV4ErMyMt5IkyLwgZx6XA++SJJLgcXVEPNfA+lUuo7ScPTP9f8p8fyanP/cmvaRXS7pV0mOS1gOnUr5t6jk2kpLCocBfZKbdDWgD7sxs9x+k6aV1ym73vH2QTas3v38lKU39l6SHJJ0JEBHLSEopi4A1kq6S9KKcZZVt44joT5ef3cbV9o+NMAcaG48eJikpzMh0bRHxDUkdwMUk1SftETEDuJfkCrlkOI8kf4Qk0JXMAjZTfqJPFhLxc5KS0etIqoWurBynwWWUlvOHwWY2x9dJqvX2iojpwEWUb5uGRMSPSUoh/5YmrSUJcPtn9sn0SBoOADwKzMzMYq+82Wa+15xfRDwVER+JiH1ISnAfLt2LiYivR8TfkmzDIKmCq1S2jdOLgb0YmW1sg+RAY0VokbR9phvs/zYuBk5Nr84laYf0JveOwA4kJ5fHACS9m6REM1K+AXxI0t5Kmvb+C0kLtc1Vxr+C5B7O5oj4aYPLuAF4qaR3SZoi6R+A/YDrh5t5kvsfj0fEs5IOJgmAQ/VF4I2SXpGWCC4GzpO0O4CkPSW9OR33auDdkl4uqY2t91py1ZufksYgL0kDxJ+BPqBP0sskHZbeW3uWJFj15SziauCtkuZIaiG55/Mc8D/D2B42RA40VoQbSE4ApW7RYCaOiKXAKSQn8CdIqlBOTof9luSexc9IShkHAP89MtkGknsNVwI/AZaTnMw+WGP8K0kCXaOlGSJiHXAkyclvHfBx4MhIGiMM12nAJyU9RXKyv3qoM4qIx0gC6Tlp0idI9sXPJf0Z+CHJPSwi4kaSxg23puP8LJ0mW5VYqer8gH3T/g3pvC6IiNuA7YDPkpSI/kjS4OPsnLw/QNI44/x03KNImm4/P5htYCNDEX7xmdlQpc1x1wCvjIgHxzo/40XaGu9eksYR1UqDNkm4RGM2PN3AHQ4yIOltklol7Uxy3+R7DjIGSWsaMxsCSStIbrQP+n8qE9Q/kjQg6AN+TFKNZ+aqMzMzK5arzszMrFCuOquw6667xuzZs8c6G2Zm25Q777xzbUTsljfMgabC7NmzWbp06Vhnw8xsmyKp8mkXW7jqzMzMCuVAY2ZmhXKgMTOzQjnQmJlZoRxozMysUA40ZmZWKAcaMzMrlAONmZkVyoHGzGwC6r2nl9lfnE3TuU3M/uJseu/prZleJAcaM7MxNtIn/957epn/vfmsXL+SIFi5fiXzvzef075/2oD04685nl0/v2uhAceBxrYdvb0wezY0NSWfvcVfiZkVrVpQGM6Jf8EtC9i4aWNZ2sZNG1ly55IB6QDrnlk37GXW4kBjo2c4gaK3F+bPh5UrISL5nD/fwca2edWCwoJbFgx5nqvWr8pN74u+qtMMd5m1ONBYdSNZgsgLFMcfD7vu2th8FyyAjRVXYhs3JvOQks6lHNsGVQsK1dIbMWv6rBHNy3A50NhAvb0wbVpyEh+pEkReoABYt66x+a5q4Acw3Dy6am7iGsf7tlpQGGqwAHjLvm9BqCytsn+kl1mLA81kV/kDPO00eM974OmnB467cSOcfvrQfrC1AsXGjUkgqpXHpgYP1WrzqnWi6e1NSlYjGVjH8YltPPnpZ09j9S5T6JdYvcsUfvrZAt7+3NvL5ve9p2zfbn7fe8bNPlk8ZzFtLW1laW0tbSyes3hI8+u9p5fLf3M5wda3JwuV9ecZzjLrigh3me6ggw6KSaOnJ6KtLSL5+SWdVN5fr2trS+ZTT0dHY/Pr6CifX14e63VS/fUs5bve/Ds6Rma7NrqdBruou3ui47yO0CJFx3kd0XN3/jIaHW803f6Z7tjQUr69N7QQt3+me0jzq7aOT+3Rnrtvn9qjfSRXZ1iGs38qp23/XHuwiAFd87nNueksYkSOCWBpVDmvjvmJfbx1kyrQNHrybyQ41DOYgJE9KQ81j9mAVWUeD+/cHM/MmFZ/Xu3t5d8rA0ZPT7IMKflszz+xNbydsvOqEZx67u6JtsVtZSeMtsVtA04YjY5XhO7ru7ec4JrPbY7u67cGkYd3bq66Xwar5+6eOP7vmmL5dKIPYvl0Yt5xRPf13dFXZb/2w0iu6pDc/pnueHjn5uhL13uwQbbn7p44+R0tA9a7WkAp8jhwoBlEN2KBZhAnjDEz2NJLta6yBFFNT0/1k3C1k/Jw8lgKWFXm0Vc62Qy2a23duj8HE0DrbKfbP9MdT7cofx1ydJzXUfXqtNHxiizpdF/fnbvcUrCpFgD6cgJAvXye8g87xDNN5fN5pik56S6fXn05Qy09ZQ01WIxEie6DXe2588gLNkXvbweaQXQjEmhqVUkNM+iM6IEymiWaiK3BdzAn5WrjT5sW0Zx/RTwgb1WC22Y1kId66zyYbVhjO/Xc3RMrZ+Qv7+Gdm3P3sxYp90SuRWpovKKvcCurakon/b50W6xra8pd3/6K30nP3T3R+qnWsnm1fqq1LJ9rpuZv8/UtRNdxqhrUVkxnWOs7nGBRq0RXL3iVhle7UNqk8hLOaJRgJ3WgAeYCDwDLgDPrjT/cQNPTE/Fwc0fNE84G2uLi1u5Y1dQRfSgebu6I27vrHwQ9d/dE67nlJ4bWc4dxAPX0xKbW8oDYT+0SROXwTa0N3nvo6YlnpwziXkvppJyTxw20xSk79GyJH83NEX3V8i1VDTTVfqT9ULfk1Y9izod6alfLVPZ3d1duki2F3uaPdtS8ws/bz9VKKs0f7SgrSFcbT4uaGpq+0pwP9QRndAQLFZzREXM+NHCknp4IFpYHl8r12zylOZ5trr6Nn5nSGvPmtgcL84Nk05ntW/Z/rX0577iByy4bfkxLcEByPLW3l1dC9PQk1zTZwym7G4dT/VcrT7WCV15wq3m+aSFO6JyzZX2yh/YIXf9GREzeQAM0A78H9gFagd8A+9WaZjiBplSQqXrSKzt5lI+zgba6wab90x1lP9zS1Ur7pzuGnN+TW3piOUnAW05HfIXu2ED1gNAHZeOf3NLT0AG6dlpHwz+MbHVRXh7n0TNgkuVUmX/pTF7lB52Xvob2aG+PeKq9ep6Xt7THvKNbYlO9UlGm++OOW28+D1iv6VS9Kl8+PTmxVu7n7gt6ggXlFx6c3RYcsHX7tLUlgWHeMRX1+Mc2Vz2Bs1B5uyIi0iBzdvky5x3dEita27dcNH11Tk+0tUXMO1Z1T4hrmneI5TtWvzIvrXvecc9CknU9o6NmFeiKnZpj+U75pafSiXje3PYBg1paIubN7I7lOyYli+U7Nse8md0BW4PNYKr/Kq2anh+kqq3LqunNNaeruZ23U0yZUrsSYLjtVSZzoHkNcFOm/yzgrFrTDCfQlGpRqp706nQPN3fUnP+84/KvdOYdV/+grpXfym4ePbGJ/CNyOR0DkhupOWsk+PZDrKC8dNdozdQ8egYGyNIvp8pM1kwlNkyp2J60bQlkJ7f0xLO0DJju2Sbi/Fe0Vj2JVjtRZE8+H2wfmN9nmhhwhV9W376wvEqsoyO2nGhLpQuO6C7vP6AnutQTG9RaPt8pNW4an1G+j7P7lzM6BlSHDTgm0224fPv6DS36SIJateOjj2QZldvl2eY0/2nQqxakt8zjwDk1g97y6QzYlvMOnDPg+OiDOH/fF0VzWmBZsVP+72TFTvVLNKe8vHpDhVrHz2CmyR6TeRdold1QGlluOTYmcaB5O3BJpv8E4N9zxpsPLAWWzpo1a8gbunThnHvSa+hAqn2zePmOVU7+Ow6+lU42v3ndPHJOTmrNPVgbaQvQSPAtnXSyV1aDaQswj60lhGx15O3dA/dH6Sp23szumqWlefTEmqYdoj/9sfaTnNSqndg2qXbJpN72WDM158p90dYAULn/sutcKmVVlnCWt+RXA5ZKC+WlGYKPtZcFquz+ZWH5/Z5qN9rX0N5QQ4vShUu17bFJNUqeU8tLOlVLRel2WTO1dnVpab+Wtn21/dhPErgikhLPgIuVKcS8mfXv0UiDCxql33m180C97Z13kVjZNdquJ89kDjTvyAk059eaZiRKNOUnvYH1w9UOrnolmuEU0+vld0B3QE/MO7qiuuXolrJqmVLXyFXQu/aqf/W2vKV9wDyH014hW6ApOyFXqX6r1s2bO7BlT61SSyMlz1pX8CxkwAmds9ui/dDyeo1qpaLsybLW/Yk+BgaaAVVUR7eULZePlf9Ho9F7VHldtvSYd3FWbx79OeNU9m+gLc4/cIdB3dNoZPlrprLl+MyrXmvkN9HREVUD9YD1mEKc8vIkeJ3y8vzgVu/3VbqQq9W5RDOEbrSrzsrr3dOD7riBP97zX9k0sLTQwD2aavcMnmrvGHJ+q7bMragi2dJ9rL2seqHloMbu0Uw7p/rN7i0n4kwgK11ZDeX/mpU/nGz/gIAzc2BVU+U8qp0M8rrl208LPtYeP9ibslLQD/Ym+PjWezRrd8kvZWyiKfpQrGnaIdZs37TlODp+dveA7VzrHlJ2u1YtYe2ksmNzzdT8qrtT3r4139v9c3uc37m1pDGk5uEQm2jOLT2W9s3moe5wSi2ukv17vHoGtf8a7Ur/wRnOf3N7epKLmLwGEc9B1f3f0xNx/OyBwa1ercEKOnyPpogOmAI8BOydaQywf61phtXqLK+FVJU27fPmtped8L46p7Ejs3L+Dbf6qj7Lsr/7dHcnN0EHXFFX6Rpt9aZFqvqD36TMNkrvD2SvrLov6Inmj3bUDAbVOmnrDdC8q+YB+ydzM12K4IDBtSw7/8Ad4vyd5+QOu2j3OVvWKe//D7VO2rn7ucF6xXVtTbnHzX0v26+hqptsld+/d9YvRTQSfEpX1+3t+aXWoQawZN4EJK3Fenpqt+6qN6+aLROr/IYG83PsvqAn1myfv4yHm6u3/ssus9RaLq+6u9Q9nV7I3t7ds6W163I64l1psHers2F2wFuA/01bny2oN/6wAk2Vep6qLWfmJnXh7Z8exP9hRuGPoD09SXPbRgJN6Y9g9XSc11GzSinb4il7ZVXtX+37fWZO8M9py6lSlxOEsruk2hXfgHsVH2vfOt0ZHYMr0UynakOKTWy9l6ZF5aWJhlqvVdZrNFiv2C/yrygaDFTZqtlNTVWWQf17G2XbiY7y/VxRMhhOoKncTtUeQdPINq8WpP6843aD+k3V0l8tH4O8YdJ9QXnrwtJ/adbu0l79cUsj+GikWoFGyXAr6ezsjKVLlw5t4qamZPdV6AeOPw4u/h7ssGlr+tMtcMpR8I0DkwfaLTlqCV0HdA1t2UPUe08vC25ZwKr1q5g1fdaWh+q957vv4fn+5xuahxD9C/trjnPa90/jwqUXMu9u+JdbYNZ6WDUdzp6TrH9J84YOLn/FCrrSzTD7i7NZuX5l4yv0fBt8bwnc00VbGyxZkjxjc+VK6KOJJvL3T/Oi8rT2qe1w45dY9/oTmHdPDNh3AbnPwu1P0/OGBSR3ZnLWq29RA0+4laA/s51Lr17Ieyp2VkcHrFhRnjZ7drJRGrBhj3amPbIWgFD+M4ADaFqUfJ9398BjPevpFvjHN7az05Ff4oLurcd7b2+yr1atgrXalV361+VO39/URFN/leOttNO7Mr+j9KGaU57dejxv3r6V3le28PY7nq6az83btzLl3e9l05KLaOnbetxsahYtl19ZvozhqLYv8vZbrdlU+a10TO9gxRkrRmw51Ui6MyI684b56c0jaMMLd8lNXzU9OblWHtA7bErSodiXDlWT92a/d3/33Zz4nRMbDjLQ2KPFb3jwBiAJKnt/KDmx7/2h8iDTqjYuP3Hxlt9vby+sfHKQ78do3QhzFtDRsfV8s3gxtBzUy6od8w/3VdMHpq17Zh1PvWE+PLML3zgwuSBYMT0JJCumw+Nt+Y9cX9XSTl+Vn1V/5gnUlU/szcvDALMqtnNXV7KSHR1JEGpvh9bW8nHa2pINMCCjjW3Xzdu3Mu1fv7SlX83NueP1ZTZH5fZ6bGrSlbbdKUdB78HruPyJijc6HtgLZ8yGhU0smgd9LVPKF9LaCj09NF1xBZu3L1/PgGT9K4MMQFcXUy65dOt26uhgyiWXMuWi/+ADx7aU5XPtVAixZRwuuCAJKplpRzTIQLJ/2sqf3lx1v9VQ97021fZ5g8fCcDjQjKCzD0uu1rKebkmu2metz58mm17US4eqyXuz36b+TfRH7dJJVqOPFq+6bpF0TTTzfCTBtvee3i0X66wf/PsxNGMVK1ZkzgUH9qKj53P2G/uq7p88z8dGdtgBtLmtLEDu//E27j/n1AEnu6fVyhd2+hKXHTx1QLkpgJ5Dpm7p7zqgiyVHLaFjegdCfOHI9gHzK1PtxNPVlVyN9vfD2rVwafkJNffECwODVlZ7e9kJuWz6+fMHjB7ARQeVp111oLZsr90/AS/4hAZcXGQvrioves7fdx3vO1Zs2GNrXrg0zUtO4FBPT7L+1QJAdjulB0fXAV0cfs7XOHRRB1MWiVf9Swc3/aIH9QdlB1DOtCOq8oKh1n6roe57bart81rHwghx1VmF4VSdNZ3bxDvvjtyqoVVfbGKvJweewFdMT358kCniVpGtWpg1KznvDOeYbzq3icipSqqlfWo701qnlVW1NVLdN5gqsLaWNqbevIR1t3XBAb1w1PykpDIIHdM7tuQtu+xs1d0jOzfzyTdtz8Uvz3n3TkqIK4+7ckD1YtcBXVt2SKxayR9mNPOJN/Tx36/rYOX6lZx/PZx6JzRHcrV/0UHwf4+sU8XY28uGj51O26PrWDcVmtXEzs/0o1kdw9/ZOcsaUO0mwamnwgUX1J72tNOSE2FfH/1NTVzcCae+Zet6tbW0cdJfncQND96wZZtV2/elate61T5WVylYZy8ey6rk8/Z5XlXjENWqOnOgqTCcQFPrx/I3t69kSU49/9qpcPoRyRXglcddWfWk3dsL7z6vl02vWwDTV8H6WbTcvpivfahryMfIYO9/lE66Q7mPlPcjqOnJDvjiiuT7Ab1w7EnQXP1953lKP7Ljrzm+6jg9x/XUzFe9wDqY9Wqf2s7aj6+tOrzuiWKkjdCVS959vsr81gsk1S56Grn/Z1vV3RcjfbWa4UAzCMMJNLVOFAtuWcBrb1/Jl26EXZ8pv1lcahTw9W9X3xe7vqGXda+tuLJ/vo32/1nC2luHdqAM9uTf3dnNBW+tc7VbZ3m1TvplQnDNlTAnDawbd4Ht/gxTqty5raJjeger/7yavhgYpJrVzOZ/3kzvPb2cfuPprHum/OZza3MrEcGm/q3LrDzxDyZY1ws0E/mqvl4QncjrPlm4McAoqax375jeseWHtHjOYr5xoHi6dWCLpB02wed+VHtXrHvFgoHVR60bk/QRzG93ZzctTS0Dxh1ukCktr2N6R0Pj7tC0C/P2eTfLv7aSvnOD5UvWMe/efnZQ+5a89hzXQywMYmFUfR/6qvWrcoMMsCW964Au1n58LT3H9ZRtix1bdywLMjCw0cZg7qs9/szjNYfXvZm7Dav124CRf52xjS8u0VQYVvPmOrRI9J2bH937gaYa+0KLmkA5w0PEopGtWmikKmQ48z7hmhNq3htqa2mj625x3jVPD2gOftbft/PlnoGlglpXxMCQrpYbqc4ZTImm3vIm+1V9kcedFc8lmvFifUfVZqz1mre2t+S3DKmWPhxdB3Sx4owV9C/sZ8UZK0b0x951QBendp46oARS6i9d6Z79g4H/b9hhE3z4+vz/VtS6Ih7q1XLdVjxVltvS1EJrc3kLskaWN9mv6os87mxsOdCMova7FnP2nPwm0F84sr3mtF86ejGtKj8JtaqNLx297Z2ELnjrBVx53JVl1ShXHnclsTC2nGAaaQ6eVatqpl61TTWNnPjz5v21Y7/GpcdcOujlDTWfZuOdq84qFFl11tsLJ37zNP6h5cKyJtD/PKeFNy/6GkDNqoPJVLWw4UW7Mu3RgaWX7L/UR8Nk2uZmw+FWZ4NQZKCBJNicfklvchN/+iraW2ZtKZWMatPW8a7KY0MG/IHQzMYFB5pBKDrQVDPZbwTnKrDNv5mNrFqBZkpeoo2+idy0dcjSx42Y2bbNjQHGiUZaOJmZbYscaMaJyd601cwmLgeaccJNW81sonJjgAqj0RjA97jNbKLxkwHGkdKTuleuTF7GuXJl0t/bW39aM7MR09ubvHWzqSn5LPAk5EAzyhYsGPjm3Y0bk/S6RvHAMLMJbJSveF11VqHoqrOmpmS/Vqp8HfwABb+0yMwmkdmzk+BSqaMjeYvoELjqbBz5wC69LGc2fTSxnNnMI7mCqPs21WEVhcxs0qlVA7Kqyv/zqqUP07gLNJL+VdLvJN0t6TuSZmSGnSVpmaQHJL05kz43TVsm6cxM+t6SfiHpQUnflFTjpeyjoLeXLzw1n9mspIlgNiu5mPmc3NKb+zr4MqN8YJjZNqxe1Vi1K9u6V7xDM+4CDXAz8JcRcSDwv8BZAJL2A94J7A/MBS6Q1CypGfgKcASwHzAvHRfgc8B5EbEv8ATw3lFdk0oLFjDl+fJSyQ5s5PydFtSv/RrlA8PMtmH1akAWL06q3rPa2qh/xTs04y7QRMR/RcTmtPfnwMz0+zHAVRHxXEQsB5YBB6fdsoh4KCKeB64CjpEk4DDgW+n0lwPHjtZ65KpS+pj2eAOlklE+MMxsG1arBqT0/4qNG6G5OUnv6Cj0fu+4CzQV3gPcmH7fE3g4M2x1mlYtvR14MhO0SukDSJovaamkpY899tgIZr/CcEolXV3JgdDRkbQcKPjAMLNtWLVzyi67bK1SA+jr23rBWuC5ZEwCjaQfSro3pzsmM84CYDNQuoOV91L4GEL6wMSIJRHRGRGdu+222+BWZjCGWyrp6kpahPT3J58OMmaWp9q5BsakUdGYPL05Ig6vNVzSScCRwJzY2v56NbBXZrSZwCPp97z0tcAMSVPSUk12/LFRCgx+LICZFanaueaEE/LHL7hR0bj7H42kucAXgNdHxGOZ9P2Br5Pck3kRcAuwL0nJ5X+BOcAfgDuAd0XEfZL+E/h2RFwl6SLg7oi4oNbyx+p9NGZmhSvg/zMl29r/aP4d2BG4WdJdaYAgIu4DrgZ+C/wAeH9E9KWllQ8ANwH3A1en4wJ8AviwpGUk92y+OrqrYmY2joxRo6JxV6IZay7RmNmEVtBTff2GTTMzS4zBm2vHY9WZmZlNIA40ZmZWKAcaMzMrlAPNWPB7ZcxsEnFjgNFW+V6Z0lNVwX/cNLMJySWa0eb3ypjZJONAM9r8Xhkzm2QcaEab3ytjZpOMA81o83tlzGyScaAZbX6vjJlNMm51NhbG4BEQZmZjxSUaMzMrlAONmZkVyoHGzMwK5UBjZmaFcqAxM7NCOdCYmVmhHGjMzKxQDjRmZlYoBxozMyvUuA00kj4qKSTtmvZL0pclLZN0t6RXZsY9SdKDaXdSJv0gSfek03xZksZiXczMJrOGHkEj6aXAx4CO7DQRcVgRmZK0F/BGIPvs/COAfdPu1cCFwKsl7QIsBDqBAO6UdF1EPJGOM6ln55oAABMxSURBVB/4OXADMBe4sYg8m5lZvkafdfafwEXAxUBfcdnZ4jzg48C1mbRjgCsiIoCfS5ohaQ/gUODmiHgcQNLNwFxJtwE7RcTP0vQrgGNxoDEzG1WNBprNEXFhoTlJSToa+ENE/KaipmtP4OFM/+o0rVb66pz0vGXOJyn5MMvvhTEzG1GNBprvSToN+A7wXCmxVIoYLEk/BF6YM2gBcDbwprzJctJiCOkDEyOWAEsAOjs7c8cxM7OhaTTQlG6wfyyTFsA+Q1loRByely7pAGBvoFSamQn8StLBJCWSvTKjzwQeSdMPrUi/LU2fmTO+mZmNooZanUXE3jndkIJMneXcExG7R8TsiJhNEixeGRF/BK4DTkxbnx0CrI+IR4GbgDdJ2lnSziSloZvSYU9JOiRtbXYi5fd8zMxsFDTa6qwF6Ab+T5p0G/AfEbGpoHzluQF4C7AM2Ai8G5LqO0mfAu5Ix/tkpkqvG7gMmErSCMANAczMRpmSRlx1RpIuAVqAy9OkE4C+iHhfgXkbE52dnbF06dKxzoaZ2TZF0p0R0Zk3rNF7NK+KiL/K9P9I0m+GnzUzM5voGn0yQJ+kF5d6JO3D6PyfxszMtnGNlmg+Btwq6SGSZsMdpPdIzMzMamko0ETELZL2BV5GEmh+FxHP1ZnMzMysdqCRdFhE/EjScRWDXiyJiLimwLyZmdkEUK9E83rgR8BROcMCcKAxM7OaagaaiFiYfv1kRCzPDpO0d2G5MjOzCaPRVmffzkn71khmxMzMJqZ692j+AtgfmF5xn2YnYPsiM2ZmZhNDvXs0LwOOBGZQfp/mKeCUojJlZmYTR717NNcC10p6TekFYmZmZoPR6B82fy3p/STVaFuqzCLiPYXkyszMJoxGGwNcSfKisjcDPyZ5t8tTRWXKzMwmjkYDzUsi4hzg6Yi4HHgrcEBx2TIzs4mi0UBTeu/Mk5L+EpgOzC4kR2ZmNqE0eo9mSfr2yn8iedPlNOCcwnJlZmYTRt1AI6kJ+HNEPAH8BBjxVzibmdnEVbfqLCL6gQ+MQl7MzGwCavQezc2SPippL0m7lLpCc2ZmZhNCo/doSv+XeX8mLXA1mpmZ1dFQiSYi9s7pCgsykj4o6QFJ90n6fCb9LEnL0mFvzqTPTdOWSTozk763pF9IelDSNyW1FpVnMzPL11CgkdQm6Z8kLUn795V0ZBEZkvQG4BjgwIjYH/i3NH0/4J0kTyeYC1wgqVlSM/AV4AhgP2BeOi7A54DzImJf4AngvUXk2czMqmv0Hs3XgOeB16b9q4FPF5Ij6AY+W3pVdESsSdOPAa6KiOfSd+MsAw5Ou2UR8VBEPA9cBRwjScBhbH2dweXAsQXl2czMqmg00Lw4Ij5P+sfNiHgGUEF5einwurTK68eSXpWm7wk8nBlvdZpWLb0deDIiNlekm5nZKGq0McDzkqaSNABA0ouB54a6UEk/JHl2WqUFaZ52Bg4BXgVcLWkf8gNbkB8so8b4efmZD8wHmDVrVr3sm5nZIDQaaBYCPwD2ktQL/A1w8lAXGhGHVxsmqRu4JiIC+KWkfmBXkhLJXplRZwKPpN/z0tcCMyRNSUs12fEr87MEWALQ2dmZG4zMzGxoGm11djNwHElw+QbQGRG3FZSn75LcW0HSS4FWkqBxHfBOSdtJ2hvYF/glcAewb9rCrJWkwcB1aaC6FXh7Ot+TgGsLyrOZmVVR71XOr6xIejT9nCVpVkT8qoA8XQpcKulekgYIJ6VB4z5JVwO/BTYD74+IvjSfHwBuApqBSyPivnRenwCukvRp4NfAVwvIr5mZ1aDkHF5loHRrjWkjIg4b+SyNrc7Ozli6dOlYZ8PMbJsi6c6I6MwbVu9Vzm8oJktmZjZZjLs/bJqZ2cQyHv+waWZmE8h4/MOmmZlNII0GmhH9w6aZmU0eY/KHTTMzmzwaCjQRcbOkX5E8FkbA6RGxttCcmZnZhNBoq7O3AZsj4vsRcT2wWZKfhGxmZnU1eo9mYUSsL/VExJMk1WlmZmY1NRpo8sZr9P6OmZlNYo0GmqWSviDpxZL2kXQecGeRGTMzs4mh0UDzQZI/bH4TuBp4Bnh/UZkyM7OJo9FWZ08DZxacFzMzm4AabXV2s6QZmf6dJd1UXLbMzGyiaLTqbNe0pRkAEfEEsHsxWTIzs4mk0UDTL2lWqUfSbNLH0ZiZmdXSaBPlBcBPJf047f8/wPxismRmZhNJo40BfiCpkyS43AVcS9LyzMzMrKaGAo2k9wGnAzNJAs0hwM+ACfcqZzMzG1mN3qM5HXgVsDJ9vfNfA48VliszM5swGg00z0bEswCStouI3wEvKy5bZmY2UTQaaFan/6P5LnCzpGuBR4rIkKRXSPq5pLskLZV0cJouSV+WtEzS3ZJemZnmJEkPpt1JmfSDJN2TTvNlSX4rqJnZKGu0McDb0q+LJN0KTCd5EVoRPg+cGxE3SnpL2n8ocASwb9q9GrgQeLWkXUieJN1J0uT6TknXpf/1uZCkAcPPgRuAucCNBeXbzMxyDPoJzBHx4/pjDUsAO6Xfp7O15HQMcEVEBPBzSTMk7UEShG6OiMcheYoBMFfSbcBOEfGzNP0K4FgcaMzMRtV4fNT/GcBNkv6NpGrvtWn6nsDDmfFWp2m10lfnpA8gaT7p/4JmzZqVN4qZmQ3RmAQaST8EXpgzaAEwB/hQRHxb0t8DXwUOJ3mFdKUYQvrAxIglwBKAzs5OP/HAzGwEjUmgiYjDqw1Lq7hOT3v/E7gk/b4a2Csz6kySarXVJNVn2fTb0vSZOeObmdkoarTV2Wh6BHh9+v0w4MH0+3XAiWnrs0OA9RHxKHAT8Kb0idI7A28CbkqHPSXpkLS12YkkTzQwM7NRNB7v0ZwCfEnSFOBZtj5T7QbgLcAyYCPwboCIeFzSp4A70vE+WWoYAHQDlwFTSRoBuCGAmdkoU9KIy0o6Oztj6dKlY50NM7NtiqQ7I6Izb9h4rDozM7MJxIHGzMwK5UBjZmaFcqAxM7NCOdCYmVmhHGjMzKxQDjRmZlYoBxozMyuUA42ZmRXKgcbMzArlQGNmZoVyoDEzs0I50JiZWaEcaMzMrFAONGZmVigHGjMzK5QDjZmZFcqBxszMCuVAY2ZmhXKgMTOzQjnQmJlZocYk0Eh6h6T7JPVL6qwYdpakZZIekPTmTPrcNG2ZpDMz6XtL+oWkByV9U1Jrmr5d2r8sHT57tNbPzMy2GqsSzb3AccBPsomS9gPeCewPzAUukNQsqRn4CnAEsB8wLx0X4HPAeRGxL/AE8N40/b3AExHxEuC8dDwzMxtlYxJoIuL+iHggZ9AxwFUR8VxELAeWAQen3bKIeCgingeuAo6RJOAw4Fvp9JcDx2bmdXn6/VvAnHR8MzMbRePtHs2ewMOZ/tVpWrX0duDJiNhckV42r3T4+nT8ASTNl7RU0tLHHntshFbFzMwAphQ1Y0k/BF6YM2hBRFxbbbKctCA/IEaN8WvNa2BixBJgCUBnZ2fuOGZmNjSFBZqIOHwIk60G9sr0zwQeSb/npa8FZkiakpZasuOX5rVa0hRgOvD4EPJkZmbDMN6qzq4D3pm2GNsb2Bf4JXAHsG/awqyVpMHAdRERwK3A29PpTwKuzczrpPT724EfpeObmdkoGqvmzW+TtBp4DfB9STcBRMR9wNXAb4EfAO+PiL60tPIB4CbgfuDqdFyATwAflrSM5B7MV9P0rwLtafqHgS1Nos3MbPTIF/nlOjs7Y+nSpWOdDTOzbYqkOyOiM2/YeKs6MzOzCcaBxszMCuVAM4709sLs2dDUlHz29o51jszMhq+w5s02OL29MH8+bNyY9K9cmfQDdHWNXb7MzIbLJZpxYsGCrUGmZOPGJN3MbFvmQDNOrFo1uHQzs22FA804MWvW4NLNzLYVDjTjxOLF0NZWntbWlqSbmW3LHGjGia4uWLIEOjpASj6XLHFDADPb9rnV2TjS1eXAYmYTj0s0ZmZWKAcaMzMrlAONmZkVyoHGzMwK5UBjZmaFcqAxM7NCOdCYmVmhHGjMzKxQDjRmZlYoBxozMyuUA42ZmRVqTAKNpHdIuk9Sv6TOTPobJd0p6Z7087DMsIPS9GWSvixJafoukm6W9GD6uXOarnS8ZZLulvTK0V9TMzMbqxLNvcBxwE8q0tcCR0XEAcBJwJWZYRcC84F9025umn4mcEtE7AvckvYDHJEZd346vZmZjbIxCTQRcX9EPJCT/uuIeCTtvQ/YXtJ2kvYAdoqIn0VEAFcAx6bjHQNcnn6/vCL9ikj8HJiRzmf86u2F2bOhqSn57O0d6xyZmQ3beL5H83fAryPiOWBPYHVm2Oo0DeAFEfEoQPq5e5q+J/BwlWnKSJovaamkpY899tgIrsIg9PbC/PmwciVEJJ/z5zvYmNk2r7BAI+mHku7N6Y5pYNr9gc8B/1hKyhkt6s2m0WkiYklEdEZE52677VYve8VYsAA2bixP27gxSTcz24YV9uKziDh8KNNJmgl8BzgxIn6fJq8GZmZGmwmUqtj+JGmPiHg0rRpbk5lmryrTjD+rVg0u3cxsGzGuqs4kzQC+D5wVEf9dSk+rxJ6SdEja2uxE4Np08HUkDQdIP7PpJ6atzw4B1peq2MalWbMGl25mto0Yq+bNb5O0GngN8H1JN6WDPgC8BDhH0l1pV7rn0g1cAiwDfg/cmKZ/FnijpAeBN6b9ADcAD6XjXwycVvBqDc/ixdDWVp7W1pakm5ltw5Q04rKSzs7OWLp06dgsvLc3uSezalVSklm8GLq6xiYvZmaDIOnOiOjMG1bYPRobgq4uBxYzm3DG1T0aMzObeBxozMysUA40ZmZWKAcaMzMrlAONmZkVyoHGzMwK5UBjZmaFcqAxM7NC+ckAFSQ9BqwEdiV5Edtk5HWfnLzuk9NIrXtHROQ+/t6BpgpJS6s9TmGi87p73Scbr3ux6+6qMzMzK5QDjZmZFcqBprolY52BMeR1n5y87pNT4evuezRmZlYol2jMzKxQDjRmZlYoB5oKkuZKekDSMklnjnV+iibpUklrJN2bSdtF0s2SHkw/dx7LPBZB0l6SbpV0v6T7JJ2epk/4dQeQtL2kX0r6Tbr+56bpe0v6Rbr+35TUOtZ5LYKkZkm/lnR92j8p1htA0gpJ90i6S9LSNK3Q496BJkNSM/AV4AhgP2CepP3GNleFuwyYW5F2JnBLROwL3JL2TzSbgY9ExMuBQ4D3p/t6Mqw7wHPAYRHxV8ArgLmSDgE+B5yXrv8TwHvHMI9FOh24P9M/Wda75A0R8YrM/2cKPe4daModDCyLiIci4nngKuCYMc5ToSLiJ8DjFcnHAJen3y8Hjh3VTI2CiHg0In6Vfn+K5KSzJ5Ng3QEisSHtbUm7AA4DvpWmT8j1lzQTeCtwSdovJsF611Hoce9AU25P4OFM/+o0bbJ5QUQ8CskJGdh9jPNTKEmzgb8GfsEkWve0+uguYA1wM/B74MmI2JyOMlGP/y8CHwf60/52Jsd6lwTwX5LulDQ/TSv0uJ8ykjObAJST5vbfE5ikacC3gTMi4s/Jxe3kEBF9wCskzQC+A7w8b7TRzVWxJB0JrImIOyUdWkrOGXVCrXeFv4mIRyTtDtws6XdFL9AlmnKrgb0y/TOBR8YoL2PpT5L2AEg/14xxfgohqYUkyPRGxDVp8qRY96yIeBK4jeRe1QxJpQvQiXj8/w1wtKQVJFXjh5GUcCb6em8REY+kn2tILjAOpuDj3oGm3B3AvmkLlFbgncB1Y5ynsXAdcFL6/STg2jHMSyHSevmvAvdHxBcygyb8ugNI2i0tySBpKnA4yX2qW4G3p6NNuPWPiLMiYmZEzCb5ff8oIrqY4OtdImkHSTuWvgNvAu6l4OPeTwaoIOktJFc4zcClEbF4jLNUKEnfAA4leVT4n4CFwHeBq4FZwCrgHRFR2WBgmybpb4HbgXvYWld/Nsl9mgm97gCSDiS56dtMcsF5dUR8UtI+JFf6uwC/Bo6PiOfGLqfFSavOPhoRR06W9U7X8ztp7xTg6xGxWFI7BR73DjRmZlYoV52ZmVmhHGjMzKxQDjRmZlYoBxozMyuUA42ZmRXKgcbMzArlQGNmZoXys87MxhFJ5wBdJA93XQvcCawH5gOtwDLghIjYKOky4Flgf+AFwIcj4vqxyLdZLS7RmI0TkjqBvyN5kvRxQOldIddExKvSd8fcT/m7UmYDryd57P1FkrYfvRybNcaBxmz8+Fvg2oh4Jn1HzvfS9L+UdLuke0hKO/tnprk6Ivoj4kHgIeAvRjfLZvU50JiNH9XeUXAZ8IGIOAA4F8iWWiqfIeVnStm440BjNn78FDhK0vbpe3LemqbvCDyavtagq2Kad0hqkvRiYB/ggdHLrllj3BjAbJyIiDskXQf8BlgJLCVpCHAOyVOlV5I8bXrHzGQPAD8maQxwakQ8O6qZNmuAn95sNo5ImhYRGyS1AT8B5kfEr6qMexlwfUR8K2+42XjhEo3Z+LJE0n4k92EurxZkzLYlLtGYmVmh3BjAzMwK5UBjZmaFcqAxM7NCOdCYmVmhHGjMzKxQ/x+QIQPaZ40b/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute error for linear regression:\n",
      "2064264.2708748104\n",
      "Absolute error for linear polynomial regression:\n",
      "1294442.8600765418\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "plt.scatter(inputs[batch][:,0], output[batch], color = 'blue') \n",
    "\n",
    "\n",
    "plt.scatter(inputs[batch][:,0], lin_reg.predict(inputs[batch]), color = 'green') \n",
    "plt.scatter(inputs[batch][:,0], lin_reg2.predict(input_augmented[batch]), color = 'red') \n",
    "plt.title('Linear Polynomial Regression') \n",
    "plt.xlabel('gap') \n",
    "plt.ylabel('acceleration') \n",
    "  \n",
    "plt.show() \n",
    "print(\"Absolute error for linear regression:\")\n",
    "print(np.linalg.norm(output- lin_reg.predict(inputs)))\n",
    "\n",
    "print(\"Absolute error for linear polynomial regression:\")\n",
    "print(np.linalg.norm(output - lin_reg2.predict(input_augmented)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.96967012e-09  3.74953253e+02 -9.20186014e+01  8.09118238e+01\n",
      " -2.85719076e+01  2.09853442e+01 -1.69779932e+01 -6.05561401e+00\n",
      "  6.74123780e+00 -1.34861473e+00  7.82988591e-01 -9.89422186e-01\n",
      "  7.71501609e-01  6.40512244e-01 -7.74690850e-01  2.14306370e-01\n",
      " -1.86967636e-01  3.07246760e-01 -1.26104161e-01 -7.78552120e-03\n",
      " -7.02698905e-03  1.23857902e-02 -9.48350813e-03 -1.17947790e-02\n",
      "  1.51038322e-02 -4.70422058e-03  6.16588288e-03 -1.15731445e-02\n",
      "  5.84367706e-03 -2.44086036e-04 -1.38417984e-03  3.53731864e-03\n",
      " -2.20065928e-03 -1.32796031e-04  2.76768110e-04]\n",
      "Help on LinearRegression in module sklearn.linear_model.base object:\n",
      "\n",
      "class LinearRegression(LinearModel, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin)\n",
      " |  LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : boolean, optional, default True\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup for n_targets > 1 and sufficient large problems.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  intercept_ : array\n",
      " |      Independent term in the linear model.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_ # doctest: +ELLIPSIS\n",
      " |  3.0000...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array_like, shape (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with `metrics.r2_score`. This will influence the ``score`` method of\n",
      " |      all the multioutput regressors (except for\n",
      " |      `multioutput.MultiOutputRegressor`). To specify the default value\n",
      " |      manually and avoid the warning, please either call `metrics.r2_score`\n",
      " |      directly or make a custom scorer with `metrics.make_scorer` (the\n",
      " |      built-in scorer ``'r2'`` uses ``multioutput='uniform_average'``).\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lin_reg2.coef_)\n",
    "print(help(lin_reg2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2e1d73d14316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin_reg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Polynomial Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(x, y, color = 'blue') \n",
    "  \n",
    "plt.plot(x, lin_reg2.predict(poly_reg.fit_transform(x)), color = 'red') \n",
    "plt.title('Polynomial Regression') \n",
    "plt.xlabel('gap') \n",
    "plt.ylabel('speed') \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do: have a list of other regression techniques we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do: using the code for neural network, add the neural network technique here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    return ds\n",
    "\n",
    "nb_weights = 100\n",
    "\n",
    "class neural:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],nb_weights) \n",
    "        self.weights2   = np.random.rand(nb_weights,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['gap', 'speed', 'lead_speed']].to_numpy()\n",
    "y = df[['acceleration']].to_numpy()\n",
    "n = neural(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        gap      speed  lead_speed  acceleration  new_speed  \\\n",
      "0           0   0.000000   0.000000    0.000000      0.000000   0.000000   \n",
      "1           1  16.495853   2.538292   12.439410      0.985249   2.636817   \n",
      "2           2  24.319829   3.049309    1.267029      0.910581   3.140367   \n",
      "3           3   3.451395  11.844214   26.573875      0.639911  11.908205   \n",
      "4           4  47.824531  15.410674   12.011722      0.272340  15.437908   \n",
      "\n",
      "    delta_x  \n",
      "0  0.000000  \n",
      "1  0.258755  \n",
      "2  0.309484  \n",
      "3  1.187621  \n",
      "4  1.542429  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "#     if i%10==0:\n",
    "    print(i)\n",
    "    n.feedforward()\n",
    "    n.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute error for neural network:\n",
      "2183911.6558572417\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute error for neural network:\")\n",
    "print(np.linalg.norm(y - n.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "# inputs = gap, speed, lead speed\n",
    "# output = acceleration\n",
    "inputs = df.iloc[:, 1:4].values\n",
    "output = df.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=3, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error', 'MAE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000000 samples\n",
      "Epoch 1/10\n",
      "3000000/3000000 [==============================] - 12s 4us/sample - loss: 4231.0585 - mean_squared_error: 4231.0527 - MAE: 18.0914\n",
      "Epoch 2/10\n",
      "3000000/3000000 [==============================] - 12s 4us/sample - loss: 3480.7784 - mean_squared_error: 3480.7761 - MAE: 16.2855\n",
      "Epoch 3/10\n",
      "3000000/3000000 [==============================] - 12s 4us/sample - loss: 2988.0755 - mean_squared_error: 2988.0732 - MAE: 15.0980\n",
      "Epoch 4/10\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 2476.2759 - mean_squared_error: 2476.2722 - MAE: 14.0142\n",
      "Epoch 5/10\n",
      "3000000/3000000 [==============================] - 12s 4us/sample - loss: 2015.6771 - mean_squared_error: 2015.6772 - MAE: 13.0680 - ETA: 5s - loss: 2098.4606 - mean_squared_error: - - ETA: 0s - loss: 2036.9589 - mean_squared_error: 2036.9594 - MA\n",
      "Epoch 6/10\n",
      "3000000/3000000 [==============================] - 14s 5us/sample - loss: 1624.1902 - mean_squared_error: 1624.1892 - MAE: 12.0140\n",
      "Epoch 7/10\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1348.4388 - mean_squared_error: 1348.4380 - MAE: 11.3560\n",
      "Epoch 8/10\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1054.7423 - mean_squared_error: 1054.7421 - MAE: 10.70753s - loss: 1066.0598 - mean_square - ETA: 1s - loss: 1057.5548 - mean_squared_\n",
      "Epoch 9/10\n",
      "3000000/3000000 [==============================] - 11s 4us/sample - loss: 834.3312 - mean_squared_error: 834.3309 - MAE: 10.08625s - loss: 859.3129 - mean_squared_error: 859.3124  - ETA: 3s - loss: 838.9545 - me\n",
      "Epoch 10/10\n",
      "3000000/3000000 [==============================] - 8s 3us/sample - loss: 734.6113 - mean_squared_error: 734.6110 - MAE: 9.7742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12ebbc588>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, output, epochs=10, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(inputs, output)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000000 samples\n",
      "Epoch 1/10\n",
      "3000000/3000000 [==============================] - 2s 1us/sample - loss: -11911.2537 - accuracy: 3.3333e-07\n",
      "Epoch 2/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -103007.2598 - accuracy: 3.3333e-07\n",
      "Epoch 3/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -433472.1084 - accuracy: 3.3333e-07\n",
      "Epoch 4/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -1153734.0869 - accuracy: 3.3333e-07\n",
      "Epoch 5/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -2338749.2946 - accuracy: 3.3333e-07\n",
      "Epoch 6/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -4046378.3342 - accuracy: 3.3333e-07\n",
      "Epoch 7/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -6324141.9600 - accuracy: 3.3333e-07\n",
      "Epoch 8/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -9207945.8650 - accuracy: 3.3333e-07\n",
      "Epoch 9/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -12727553.6900 - accuracy: 3.3333e-07\n",
      "Epoch 10/10\n",
      "3000000/3000000 [==============================] - 1s 0us/sample - loss: -16911018.0133 - accuracy: 3.3333e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x120ec3080>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, output, epochs=10, batch_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000/3000000 [==============================] - 104s 35us/sample - loss: -19239875.1145 - accuracy: 3.3333e-07\n",
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(inputs, output)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000000 samples\n",
      "Epoch 1/100\n",
      "3000000/3000000 [==============================] - 54s 18us/sample - loss: -1539575950.3244 - accuracy: 3.3333e-07 - los\n",
      "Epoch 2/100\n",
      "3000000/3000000 [==============================] - 75s 25us/sample - loss: -14346448536.0768 - accuracy: 3.3333e-07\n",
      "Epoch 3/100\n",
      "3000000/3000000 [==============================] - 40s 13us/sample - loss: -51535785135.6117 - accuracy: 3.3333e-07\n",
      "Epoch 4/100\n",
      "3000000/3000000 [==============================] - 41s 14us/sample - loss: -126134454220.8683 - accuracy: 3.3333e-07\n",
      "Epoch 5/100\n",
      "3000000/3000000 [==============================] - 43s 14us/sample - loss: -250660446341.3931 - accuracy: 3.3333e-07\n",
      "Epoch 6/100\n",
      "3000000/3000000 [==============================] - 43s 14us/sample - loss: -437091542570.8032 - accuracy: 3.3333e-07\n",
      "Epoch 7/100\n",
      "3000000/3000000 [==============================] - 46s 15us/sample - loss: -700118801877.8113 - accuracy: 3.3333e-07\n",
      "Epoch 8/100\n",
      "3000000/3000000 [==============================] - 39s 13us/sample - loss: -1050370997128.3969 - accuracy: 3.3333e-07\n",
      "Epoch 9/100\n",
      "3000000/3000000 [==============================] - 37s 12us/sample - loss: -1501688340472.0811 - accuracy: 3.3333e-07\n",
      "Epoch 10/100\n",
      "3000000/3000000 [==============================] - 37s 12us/sample - loss: -2065583745291.8784 - accuracy: 3.3333e-07\n",
      "Epoch 11/100\n",
      "3000000/3000000 [==============================] - 41s 14us/sample - loss: -2755755978382.8140 - accuracy: 3.3333e-07\n",
      "Epoch 12/100\n",
      "3000000/3000000 [==============================] - 58s 19us/sample - loss: -3581591388081.3569 - accuracy: 3.3333e-07\n",
      "Epoch 13/100\n",
      "3000000/3000000 [==============================] - 53s 18us/sample - loss: -4561248520044.5439 - accuracy: 3.3333e-07\n",
      "Epoch 14/100\n",
      "3000000/3000000 [==============================] - 51s 17us/sample - loss: -5703688972848.3330 - accuracy: 3.3333e-07\n",
      "Epoch 15/100\n",
      "3000000/3000000 [==============================] - 43s 14us/sample - loss: -7022563249671.3730 - accuracy: 3.3333e-07\n",
      "Epoch 16/100\n",
      "3000000/3000000 [==============================] - 58s 19us/sample - loss: -8531669538238.1914 - accuracy: 3.3333e-07s - loss: -8523057\n",
      "Epoch 17/100\n",
      "3000000/3000000 [==============================] - 66s 22us/sample - loss: -10237361126270.5664 - accuracy: 3.3333e-07 - loss: -10167221670932.4590 - accuracy: 3. - ETA - ETA: 1s -\n",
      "Epoch 18/100\n",
      "3000000/3000000 [==============================] - 77s 26us/sample - loss: -12159516146399.0957 - accuracy: 3.3333e-07\n",
      "Epoch 19/100\n",
      "3000000/3000000 [==============================] - 100s 33us/sample - loss: -14301494646490.1797 - accuracy: 3.3333e-07\n",
      "Epoch 20/100\n",
      " 286800/3000000 [=>............................] - ETA: 1:41 - loss: -15611502547269.0938 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c735272bdf1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[1;32m    788\u001b[0m               mode, 'end', step, batch_logs)\n\u001b[0;32m--> 789\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(inputs, output, epochs=100, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
